{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77db71e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report, roc_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e365948",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe8a491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "remove_outliers = True\n",
    "quantile_outlier_remove = 0.001\n",
    "\n",
    "# Error costs\n",
    "cost_fp = 1   # Cost of a legitimate transaction being classified as fraud\n",
    "cost_fn = 10  # Cost of a fraudulent transaction being classified as legitimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9f9f663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/gzdekzlkaya/credit-card-fraud-detection-dataset\n",
      "License(s): CC-BY-SA-4.0\n",
      "credit-card-fraud-detection-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d gzdekzlkaya/credit-card-fraud-detection-dataset\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(\"credit-card-fraud-detection-dataset.zip\", \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"credit_fraud_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c99e193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"credit_fraud_data/creditcard_fraud_detection.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5a0024",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8645fad4",
   "metadata": {},
   "source": [
    "Features:\n",
    "- V1 to V28: PCA-transformed features\n",
    "- Amount: Transaction amount\n",
    "- Time: Time since first transaction\n",
    "- Class: Target (0 = legitimate, 1 = fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca2d7351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.0000</td>\n",
       "      <td>284807.0000</td>\n",
       "      <td>284807.0000</td>\n",
       "      <td>284807.0000</td>\n",
       "      <td>284807.0000</td>\n",
       "      <td>284807.0000</td>\n",
       "      <td>284807.0000</td>\n",
       "      <td>284807.0000</td>\n",
       "      <td>284807.0000</td>\n",
       "      <td>284807.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>284807.0000</td>\n",
       "      <td>284807.0000</td>\n",
       "      <td>284807.0000</td>\n",
       "      <td>284807.0000</td>\n",
       "      <td>284807.0000</td>\n",
       "      <td>284807.0000</td>\n",
       "      <td>284807.0000</td>\n",
       "      <td>284807.0000</td>\n",
       "      <td>284807.0000</td>\n",
       "      <td>284807.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.8596</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>88.3496</td>\n",
       "      <td>0.0017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.1460</td>\n",
       "      <td>1.9587</td>\n",
       "      <td>1.6513</td>\n",
       "      <td>1.5163</td>\n",
       "      <td>1.4159</td>\n",
       "      <td>1.3802</td>\n",
       "      <td>1.3323</td>\n",
       "      <td>1.2371</td>\n",
       "      <td>1.1944</td>\n",
       "      <td>1.0986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7345</td>\n",
       "      <td>0.7257</td>\n",
       "      <td>0.6245</td>\n",
       "      <td>0.6056</td>\n",
       "      <td>0.5213</td>\n",
       "      <td>0.4822</td>\n",
       "      <td>0.4036</td>\n",
       "      <td>0.3301</td>\n",
       "      <td>250.1201</td>\n",
       "      <td>0.0415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>-56.4075</td>\n",
       "      <td>-72.7157</td>\n",
       "      <td>-48.3256</td>\n",
       "      <td>-5.6832</td>\n",
       "      <td>-113.7433</td>\n",
       "      <td>-26.1605</td>\n",
       "      <td>-43.5572</td>\n",
       "      <td>-73.2167</td>\n",
       "      <td>-13.4341</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.8304</td>\n",
       "      <td>-10.9331</td>\n",
       "      <td>-44.8077</td>\n",
       "      <td>-2.8366</td>\n",
       "      <td>-10.2954</td>\n",
       "      <td>-2.6046</td>\n",
       "      <td>-22.5657</td>\n",
       "      <td>-15.4301</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.5000</td>\n",
       "      <td>-0.9204</td>\n",
       "      <td>-0.5985</td>\n",
       "      <td>-0.8904</td>\n",
       "      <td>-0.8486</td>\n",
       "      <td>-0.6916</td>\n",
       "      <td>-0.7683</td>\n",
       "      <td>-0.5541</td>\n",
       "      <td>-0.2086</td>\n",
       "      <td>-0.6431</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2284</td>\n",
       "      <td>-0.5424</td>\n",
       "      <td>-0.1618</td>\n",
       "      <td>-0.3546</td>\n",
       "      <td>-0.3171</td>\n",
       "      <td>-0.3270</td>\n",
       "      <td>-0.0708</td>\n",
       "      <td>-0.0530</td>\n",
       "      <td>5.6000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.0000</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.1798</td>\n",
       "      <td>-0.0198</td>\n",
       "      <td>-0.0543</td>\n",
       "      <td>-0.2742</td>\n",
       "      <td>0.0401</td>\n",
       "      <td>0.0224</td>\n",
       "      <td>-0.0514</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0295</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>-0.0112</td>\n",
       "      <td>0.0410</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>-0.0521</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>22.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.5000</td>\n",
       "      <td>1.3156</td>\n",
       "      <td>0.8037</td>\n",
       "      <td>1.0272</td>\n",
       "      <td>0.7433</td>\n",
       "      <td>0.6119</td>\n",
       "      <td>0.3986</td>\n",
       "      <td>0.5704</td>\n",
       "      <td>0.3273</td>\n",
       "      <td>0.5971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1864</td>\n",
       "      <td>0.5286</td>\n",
       "      <td>0.1476</td>\n",
       "      <td>0.4395</td>\n",
       "      <td>0.3507</td>\n",
       "      <td>0.2410</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>77.1650</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.0000</td>\n",
       "      <td>2.4549</td>\n",
       "      <td>22.0577</td>\n",
       "      <td>9.3826</td>\n",
       "      <td>16.8753</td>\n",
       "      <td>34.8017</td>\n",
       "      <td>73.3016</td>\n",
       "      <td>120.5895</td>\n",
       "      <td>20.0072</td>\n",
       "      <td>15.5950</td>\n",
       "      <td>...</td>\n",
       "      <td>27.2028</td>\n",
       "      <td>10.5031</td>\n",
       "      <td>22.5284</td>\n",
       "      <td>4.5845</td>\n",
       "      <td>7.5196</td>\n",
       "      <td>3.5173</td>\n",
       "      <td>31.6122</td>\n",
       "      <td>33.8478</td>\n",
       "      <td>25691.1600</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Time           V1           V2           V3           V4  \\\n",
       "count  284807.0000  284807.0000  284807.0000  284807.0000  284807.0000   \n",
       "mean    94813.8596       0.0000       0.0000      -0.0000       0.0000   \n",
       "std     47488.1460       1.9587       1.6513       1.5163       1.4159   \n",
       "min         0.0000     -56.4075     -72.7157     -48.3256      -5.6832   \n",
       "25%     54201.5000      -0.9204      -0.5985      -0.8904      -0.8486   \n",
       "50%     84692.0000       0.0181       0.0655       0.1798      -0.0198   \n",
       "75%    139320.5000       1.3156       0.8037       1.0272       0.7433   \n",
       "max    172792.0000       2.4549      22.0577       9.3826      16.8753   \n",
       "\n",
       "                V5           V6           V7           V8           V9  ...  \\\n",
       "count  284807.0000  284807.0000  284807.0000  284807.0000  284807.0000  ...   \n",
       "mean        0.0000       0.0000      -0.0000       0.0000      -0.0000  ...   \n",
       "std         1.3802       1.3323       1.2371       1.1944       1.0986  ...   \n",
       "min      -113.7433     -26.1605     -43.5572     -73.2167     -13.4341  ...   \n",
       "25%        -0.6916      -0.7683      -0.5541      -0.2086      -0.6431  ...   \n",
       "50%        -0.0543      -0.2742       0.0401       0.0224      -0.0514  ...   \n",
       "75%         0.6119       0.3986       0.5704       0.3273       0.5971  ...   \n",
       "max        34.8017      73.3016     120.5895      20.0072      15.5950  ...   \n",
       "\n",
       "               V21          V22          V23          V24          V25  \\\n",
       "count  284807.0000  284807.0000  284807.0000  284807.0000  284807.0000   \n",
       "mean        0.0000      -0.0000       0.0000       0.0000       0.0000   \n",
       "std         0.7345       0.7257       0.6245       0.6056       0.5213   \n",
       "min       -34.8304     -10.9331     -44.8077      -2.8366     -10.2954   \n",
       "25%        -0.2284      -0.5424      -0.1618      -0.3546      -0.3171   \n",
       "50%        -0.0295       0.0068      -0.0112       0.0410       0.0166   \n",
       "75%         0.1864       0.5286       0.1476       0.4395       0.3507   \n",
       "max        27.2028      10.5031      22.5284       4.5845       7.5196   \n",
       "\n",
       "               V26          V27          V28       Amount        Class  \n",
       "count  284807.0000  284807.0000  284807.0000  284807.0000  284807.0000  \n",
       "mean        0.0000      -0.0000      -0.0000      88.3496       0.0017  \n",
       "std         0.4822       0.4036       0.3301     250.1201       0.0415  \n",
       "min        -2.6046     -22.5657     -15.4301       0.0000       0.0000  \n",
       "25%        -0.3270      -0.0708      -0.0530       5.6000       0.0000  \n",
       "50%        -0.0521       0.0013       0.0112      22.0000       0.0000  \n",
       "75%         0.2410       0.0910       0.0783      77.1650       0.0000  \n",
       "max         3.5173      31.6122      33.8478   25691.1600       1.0000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25f72abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  284807\n",
      "Number of fraudulent transactions:  492\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows: \", df.shape[0])\n",
    "print(\"Number of fraudulent transactions: \", df[df['Class'] == 1].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7add2a4",
   "metadata": {},
   "source": [
    "Analyzing the correlation between the variables and the Class feature and filtering for the 1%+ corrrelated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71ab7d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V11     0.154876\n",
      "V4      0.133447\n",
      "V2      0.091289\n",
      "V21     0.040413\n",
      "V19     0.034783\n",
      "V20     0.020090\n",
      "V8      0.019875\n",
      "V27     0.017580\n",
      "Time   -0.012323\n",
      "V6     -0.043643\n",
      "V5     -0.094974\n",
      "V9     -0.097733\n",
      "V1     -0.101347\n",
      "V18    -0.111485\n",
      "V7     -0.187257\n",
      "V3     -0.192961\n",
      "V16    -0.196539\n",
      "V10    -0.216883\n",
      "V12    -0.260593\n",
      "V14    -0.302544\n",
      "V17    -0.326481\n",
      "Name: Class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "correlations = df.corr(numeric_only=True)['Class'].drop('Class').sort_values(ascending=False)\n",
    "correlations001 = correlations[correlations.abs() >= 0.01]\n",
    "print(correlations001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5caa7e",
   "metadata": {},
   "source": [
    "Now, keeping on the df only the features above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5b562ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = correlations001.index.tolist()\n",
    "selected_columns.append('Class')\n",
    "\n",
    "df = df[selected_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9586f912",
   "metadata": {},
   "source": [
    "Analyzing the outlier nonfraud cases and removing them from df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8012e29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original nonfraud: 284315\n",
      "Cleaned nonfraud:  278234\n",
      "Outliers removed:  6081\n"
     ]
    }
   ],
   "source": [
    "if remove_outliers:\n",
    "    df_nonfraud = df[df['Class'] == 0].copy()\n",
    "    df_fraud = df[df['Class'] == 1].copy()\n",
    "\n",
    "    # Columns to evaluate outliers analysis\n",
    "    cols = df_nonfraud.columns.drop(['Class','Time'])\n",
    "\n",
    "    # Create a boolean mask: True if row is NOT an outlier in any column\n",
    "    mask = pd.Series([True] * len(df_nonfraud), index=df_nonfraud.index)\n",
    "\n",
    "    # Loop over each column to find and remove 0.1% tails\n",
    "    for col in cols:\n",
    "        lower = df_nonfraud[col].quantile(quantile_outlier_remove)\n",
    "        upper = df_nonfraud[col].quantile(1-quantile_outlier_remove)\n",
    "        col_mask = (df_nonfraud[col] >= lower) & (df_nonfraud[col] <= upper)\n",
    "        mask = mask & col_mask  # keep only rows within bounds for all columns\n",
    "\n",
    "    # Filter nonfraud rows to exclude outliers\n",
    "    df_nonfraud_cleaned = df_nonfraud[mask]\n",
    "\n",
    "    # Combine with untouched fraud cases\n",
    "    df = pd.concat([df_nonfraud_cleaned, df_fraud], ignore_index=True)\n",
    "\n",
    "    print(f\"Original nonfraud: {df_nonfraud.shape[0]}\")\n",
    "    print(f\"Cleaned nonfraud:  {df_nonfraud_cleaned.shape[0]}\")\n",
    "    print(f\"Outliers removed:  {df_nonfraud.shape[0] - df_nonfraud_cleaned.shape[0]}\")\n",
    "\n",
    "else:\n",
    "    print(\"Outlier removal skipped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c4f928",
   "metadata": {},
   "source": [
    "`df` is now ready to be used at each predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0548aa1",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e0dcd8",
   "metadata": {},
   "source": [
    "Analysis of correlation between the predictive variables based on VIF.\n",
    "\n",
    "| VIF  | Interpretation                    |\n",
    "| ---- | --------------------------------- |\n",
    "| 1    | No multicollinearity              |\n",
    "| 1â€“5  | Moderate correlation (usually OK) |\n",
    "| 5â€“10 | Concerning â€” check that feature   |\n",
    "| >10  | Problematic â€” strong collinearity |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4696d1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature       VIF\n",
      "0    const  1.000000\n",
      "1      V11  1.100180\n",
      "2       V4  1.056541\n",
      "3       V2  1.155098\n",
      "4      V21  1.034565\n",
      "5      V19  1.015318\n",
      "6      V20  1.143984\n",
      "7       V8  1.050942\n",
      "8      V27  1.031940\n",
      "9     Time  1.562847\n",
      "10      V6  1.155688\n",
      "11      V5  1.247599\n",
      "12      V9  1.043921\n",
      "13      V1  1.212707\n",
      "14     V18  1.020424\n",
      "15      V7  1.218729\n",
      "16      V3  1.385468\n",
      "17     V16  1.039844\n",
      "18     V10  1.055782\n",
      "19     V12  1.040558\n",
      "20     V14  1.050773\n",
      "21     V17  1.023802\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns='Class')\n",
    "\n",
    "# Standardize features to improve stability\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = pd.DataFrame(StandardScaler().fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Add constant for statsmodels\n",
    "X_const = add_constant(X)\n",
    "\n",
    "# Compute VIF for each feature\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['feature'] = X_const.columns\n",
    "vif_data['VIF'] = [variance_inflation_factor(X_const.values, i)\n",
    "                   for i in range(X_const.shape[1])]\n",
    "\n",
    "print(vif_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b4f84c",
   "metadata": {},
   "source": [
    "There are no variables to be removed by multicollinearity.\n",
    "\n",
    "Starting the model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07579b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='Class')\n",
    "y = df['Class']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Train-test split (stratify to preserve class balance)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=35, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcd9956",
   "metadata": {},
   "source": [
    "Stepwise logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3387460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add         V7 with p-value 0.0000\n",
      "Add        V10 with p-value 0.0000\n",
      "Add         V4 with p-value 0.0000\n",
      "Add        V14 with p-value 0.0000\n",
      "Add        V12 with p-value 0.0000\n",
      "Add        V16 with p-value 0.0000\n",
      "Add         V8 with p-value 0.0000\n",
      "Add         V2 with p-value 0.0002\n",
      "Add        V17 with p-value 0.0066\n",
      "Add        V11 with p-value 0.0022\n",
      "Add        V21 with p-value 0.0464\n"
     ]
    }
   ],
   "source": [
    "def stepwise_selection(X, y, threshold_in=0.05, verbose=True):\n",
    "    included = []\n",
    "    while True:\n",
    "        changed = False\n",
    "        excluded = list(set(X.columns) - set(included))\n",
    "        new_pval = pd.Series(index=excluded, dtype=float)\n",
    "\n",
    "        for new_col in excluded:\n",
    "            model = sm.Logit(y, sm.add_constant(X[included + [new_col]])).fit(disp=0)\n",
    "            new_pval[new_col] = model.pvalues[new_col]\n",
    "\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed = True\n",
    "            if verbose:\n",
    "                print(f\"Add {best_feature:>10} with p-value {best_pval:.4f}\")\n",
    "\n",
    "        if not changed:\n",
    "            break\n",
    "    return included\n",
    "\n",
    "# Run on training set\n",
    "selected_features = stepwise_selection(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea194940",
   "metadata": {},
   "source": [
    "Cross-validation with selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e093086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated roc_auc: 0.9823 [0.9847944  0.99024637 0.96448633 0.98534908 0.98663631]\n",
      "Cross-validated f1: 0.9098 [0.95302013 0.87943262 0.88888889 0.8951049  0.93243243]\n",
      "Cross-validated recall: 0.8377 [0.91025641 0.78481013 0.81012658 0.81012658 0.87341772]\n",
      "Cross-validated balanced_accuracy: 0.9189 [0.95512821 0.89240506 0.90505206 0.90506329 0.93670886]\n"
     ]
    }
   ],
   "source": [
    "model_cv = LogisticRegression(max_iter=1000, solver='liblinear')\n",
    "\n",
    "cv_stats = ['roc_auc','f1','recall','balanced_accuracy']\n",
    "\n",
    "for stat in cv_stats:\n",
    "    cv_scores = cross_val_score(model_cv, X_train[selected_features], y_train, \n",
    "                                cv=5, scoring=stat)\n",
    "    print(f\"Cross-validated {stat}:\", np.round(cv_scores.mean(), 4), cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6650eca4",
   "metadata": {},
   "source": [
    "Final model fitting and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "20f9c2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = LogisticRegression(max_iter=1000, solver='liblinear')\n",
    "model_final.fit(X_train[selected_features], y_train)\n",
    "\n",
    "y_pred = model_final.predict(X_test[selected_features])\n",
    "y_proba = model_final.predict_proba(X_test[selected_features])[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8e6d67",
   "metadata": {},
   "source": [
    "Gets best threshold based on FP and FN costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e85bd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold = 0.08 with total cost = 217\n",
      "Confusion Matrix at Best Threshold:\n",
      "[[55641     7]\n",
      " [   21    77]]\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.linspace(0.01, 0.99, 99)\n",
    "costs = []\n",
    "\n",
    "for thresh in thresholds:\n",
    "    y_pred_thresh = (y_proba >= thresh).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_thresh).ravel()\n",
    "    total_cost = fp * cost_fp + fn * cost_fn\n",
    "    costs.append(total_cost)\n",
    "\n",
    "# Best threshold\n",
    "best_index = np.argmin(costs)\n",
    "best_threshold = thresholds[best_index]\n",
    "print(f\"Best threshold = {best_threshold:.2f} with total cost = {costs[best_index]}\")\n",
    "# print(f\"Confusion Matrix at Best Threshold:\\n{confusion_matrix(y_test, (y_proba >= best_threshold).astype(int))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22b9031",
   "metadata": {},
   "source": [
    "Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "18852973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9994977218096366\n",
      "ROC AUC: 0.9757904275856404\n",
      "Confusion Matrix:\n",
      " [[55641     7]\n",
      " [   21    77]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     55648\n",
      "           1       0.92      0.79      0.85        98\n",
      "\n",
      "    accuracy                           1.00     55746\n",
      "   macro avg       0.96      0.89      0.92     55746\n",
      "weighted avg       1.00      1.00      1.00     55746\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = (y_proba >= best_threshold).astype(int)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "plt.plot(fpr, tpr, label='Logistic (AUC = {:.3f})'.format(roc_auc_score(y_test, y_proba)))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391bb337",
   "metadata": {},
   "source": [
    "Goodness of fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c757e42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001963\n",
      "         Iterations 14\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  Class   No. Observations:               222980\n",
      "Model:                          Logit   Df Residuals:                   222968\n",
      "Method:                           MLE   Df Model:                           11\n",
      "Date:                Sun, 25 May 2025   Pseudo R-squ.:                  0.8486\n",
      "Time:                        12:41:40   Log-Likelihood:                -437.62\n",
      "converged:                       True   LL-Null:                       -2891.0\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -9.7123      0.233    -41.673      0.000     -10.169      -9.255\n",
      "V7            -0.1034      0.099     -1.039      0.299      -0.298       0.092\n",
      "V10           -0.7720      0.140     -5.508      0.000      -1.047      -0.497\n",
      "V4             1.2063      0.129      9.360      0.000       0.954       1.459\n",
      "V14           -1.1050      0.100    -11.068      0.000      -1.301      -0.909\n",
      "V12           -0.7925      0.115     -6.888      0.000      -1.018      -0.567\n",
      "V16           -0.4897      0.139     -3.515      0.000      -0.763      -0.217\n",
      "V8            -0.4427      0.061     -7.308      0.000      -0.561      -0.324\n",
      "V2            -0.2929      0.080     -3.662      0.000      -0.450      -0.136\n",
      "V17           -0.2960      0.107     -2.763      0.006      -0.506      -0.086\n",
      "V11            0.3820      0.120      3.170      0.002       0.146       0.618\n",
      "V21            0.0978      0.049      1.992      0.046       0.002       0.194\n",
      "==============================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.67 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n",
      "McFadden RÂ²: 0.8486274273751748\n"
     ]
    }
   ],
   "source": [
    "X_train_sm = sm.add_constant(X_train[selected_features])\n",
    "model_sm = sm.Logit(y_train, X_train_sm).fit()\n",
    "print(model_sm.summary())\n",
    "\n",
    "# Pseudo R-squared (McFadden)\n",
    "print(\"McFadden RÂ²:\", model_sm.prsquared)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e91c90",
   "metadata": {},
   "source": [
    "Export Coefficients, Odds Ratios and P-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fc432c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001963\n",
      "         Iterations 14\n",
      "      Feature  Coefficient  Odds Ratio       P-Value\n",
      "const   const    -9.712268    0.000061  0.000000e+00\n",
      "V14       V14    -1.105015    0.331206  1.799008e-28\n",
      "V4         V4     1.206276    3.341019  7.976078e-21\n",
      "V8         V8    -0.442683    0.642311  2.711696e-13\n",
      "V12       V12    -0.792514    0.452705  5.667241e-12\n",
      "V10       V10    -0.771973    0.462100  3.634173e-08\n",
      "V2         V2    -0.292882    0.746110  2.505880e-04\n",
      "V16       V16    -0.489718    0.612799  4.404653e-04\n",
      "V11       V11     0.381967    1.465164  1.523507e-03\n",
      "V17       V17    -0.296018    0.743774  5.725832e-03\n",
      "V21       V21     0.097840    1.102786  4.640595e-02\n",
      "V7         V7    -0.103373    0.901791  2.986682e-01\n"
     ]
    }
   ],
   "source": [
    "# Coefficients and p-values\n",
    "coefs = model_sm.params\n",
    "pvals = model_sm.pvalues\n",
    "odds_ratios = np.exp(coefs)\n",
    "\n",
    "# Combine into a summary DataFrame\n",
    "summary_df = pd.DataFrame({\n",
    "    'Feature': coefs.index,\n",
    "    'Coefficient': coefs.values,\n",
    "    'Odds Ratio': odds_ratios,\n",
    "    'P-Value': pvals\n",
    "}).sort_values(by='P-Value')\n",
    "\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceed78c7",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19a8abc",
   "metadata": {},
   "source": [
    "Since there is no correlated variables (and also givem that tree based models are not sensible for this), it's able to use already the same datasets splitted for logistic regression: X_train, X_test, y_train, y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc04858",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cv = RandomForestClassifier(\n",
    "    n_estimators=199,   # Number of trees in the forest\n",
    "    max_depth=None,     # Expand until all leaves are pure\n",
    "    random_state=92,    # For reproducibility\n",
    "    n_jobs=-1           # Use all processors for parallelism\n",
    ")\n",
    "\n",
    "cv_stats = ['roc_auc', 'f1', 'recall', 'balanced_accuracy']\n",
    "\n",
    "for stat in cv_stats:\n",
    "    cv_scores = cross_val_score(model_cv, X_train[selected_features], y_train, \n",
    "                                cv=5, scoring=stat)\n",
    "    print(f\"Cross-validated {stat}:\", np.round(cv_scores.mean(), 4), cv_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
